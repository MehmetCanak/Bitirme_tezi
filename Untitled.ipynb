{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Learning ile Atari Space Invaders oyunu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"C:\\Users\\mehmet\\Desktop\\rapor\\bitirme tezi/spaceinvaders.png\" alt=\"Space invaders\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bu not defterinde, OpenAI gym'yi ortam kütüphanesi olarak kullanarak Atari Space Invaders oynamayı \n",
    "öğrenen bir ajan uygulayacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Adım : kütüphanelerin import edilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf      # Deep Learning kütüphanesi\n",
    "import numpy as np           # matriksleri oluşturmak için kütüphane\n",
    "import gym                   # gym ortamı\n",
    "\n",
    "\n",
    "from skimage import transform # Çerçeveleri ön işlememize yardımcı olur\n",
    "from skimage.color import rgb2gray # Çerçevelerimizi grileştirmemize yardımcı olun\n",
    "\n",
    "import matplotlib.pyplot as plt # Grafikleri görüntüle\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import random\n",
    "\n",
    "import warnings # This ignore all the warning messages that are normally printed during the training because of skiimage\n",
    "                #Bu, egzersiz sırasında normal olarak yazdırılan tüm uyarı mesajlarını yok sayma nedeniyle yok sayar.\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adım : Ortamın Oluşturması\n",
    "Ortamımız Atari Space Invaders oyunudur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 592379725]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'SpaceInvaders-v0'\n",
    "env = gym.make(env_name)\n",
    "env.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çerçevemizin boyutu:  Box(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Çerçevemizin boyutu: \", env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hareketin boyutu :  6\n"
     ]
    }
   ],
   "source": [
    "print(\"hareketin boyutu : \", env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olası hareketler :  [[1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"olası hareketler : \", possible_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adım 3: Önişleme işlevlerini tanımlayın ⚙️\n",
    "preprocess_frame\n",
    "Önişleme önemli bir adımdır, çünkü eğitim için gereken hesaplama süresini azaltmak için durumlarımızın karmaşıklığını azaltmak istiyoruz.\n",
    "\n",
    "Adımlarımız:\n",
    "\n",
    "Çerçevelerimizin her birini gri tonlamalı olmalıdır\n",
    "Ekranı kırpıyoruz\n",
    "Piksel değerlerini normalleştiriyoruz\n",
    "Son olarak, önceden işlenmiş çerçeveyi yeniden boyutlandırıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    önişlem çerçevesi:\\n     Bir çerçeve alıp Gri tonlamalı yapıp yeniden boyutlandıracaz.\\n        __________________\\n        |                 |\\n        |                 |\\n        |                 |\\n        |                 |\\n        |_________________|   \\n        \\n        den\\n        _____________\\n        |            |\\n        |            |\\n        |            |\\n        |____________|\\n    e cevirip normalize edeceğiz.\\n    \\n    önişlem cercevesi yapıp döndüreceğiz.\\n    \\n    '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    önişlem çerçevesi:\n",
    "     Bir çerçeve alıp Gri tonlamalı yapıp yeniden boyutlandıracaz.\n",
    "        __________________\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |_________________|   \n",
    "        \n",
    "        den\n",
    "        _____________\n",
    "        |            |\n",
    "        |            |\n",
    "        |            |\n",
    "        |____________|\n",
    "    e cevirip normalize edeceğiz.\n",
    "    \n",
    "    önişlem cercevesi yapıp döndüreceğiz.\n",
    "    \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    # gri tonlamalı cerceve\n",
    "    gray = rgb2gray(frame)\n",
    "    \n",
    "    cropped_frame = gray[8:-12,4:-12]  #kırpılmış cerceve\n",
    "    \n",
    "    # Piksel Değerlerini Normallizelestir\n",
    "    normalized_frame = cropped_frame/255.0\n",
    "    \n",
    "    #Yeniden Boyutlandırma\n",
    "\n",
    "    preprocessed_frame = transform.resize(normalized_frame, [110,84])\n",
    "    \n",
    "    return preprocessed_frame # 110x84x1 cerceve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yığın çerçeveler\n",
    "\n",
    "raporda açıklandığı gibi çerçeveleri yığınlıyoruz.\n",
    "\n",
    "Çerçeveleri istiflemek gerçekten önemlidir, çünkü Sinir Ağımıza bir hareket duygusu vermemize yardımcı olur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_size = 4 # We stack 4 frames\n",
    "\n",
    "# Her görüntü için bir dizi olmak üzere sıfır görüntü ile deque başlat\n",
    "stacked_frames  =  deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    # Önişlem çerçevesi\n",
    "    frame = preprocess_frame(state)\n",
    "    \n",
    "    if is_new_episode:\n",
    "        # Stacked_frames öğelerini temizleyecez\n",
    "        stacked_frames = deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "        \n",
    "        # Çünkü yeni bir bölümdeyiz,aynı çerçeveyi 4x kopyalayacağız\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        \n",
    "        # Stack the frames\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "        \n",
    "    else:\n",
    "        # Deque'ye çerçeve ekle, en eski çerçeveyi otomatik olarak kaldırır\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "        # Yığılmış durumu oluşturma (ilk boyut farklı kareleri belirtir)\n",
    "        stacked_state = np.stack(stacked_frames, axis=2) \n",
    "    \n",
    "    return stacked_state, stacked_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Adım: Hiperparametreleri ayarlayacaz\n",
    "\n",
    "Bu bölümde farklı hiperparametrelerimizi kuracağız. Ancak bir Sinir Ağını kendiniz uyguladığınızda,\n",
    "hiperparamatörleri aynı anda değil, aşamalı olarak uygulayacağız.\n",
    "\n",
    "İlk olarak, modeli uygularken sinir ağları hiperparametrelerini tanımlayarak başlarız.\n",
    "Ardından, egzersiz algoritmasını uygularken egzersiz hiperparametrelerini ekleyeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL HYPERPARAMETERLERİ\n",
    "state_size = [110, 84, 4]      # Girişimiz 4 çerçeveli bir gruptur, 110x84x4 (Genişlik(Width), yükseklik, kanallar) \n",
    "action_size = env.action_space.n # 8 possible actions\n",
    "learning_rate =  0.00025      # Alpha (aka learning rate)\n",
    "\n",
    "### TRAINING HYPERPARAMETERS\n",
    "total_episodes = 50            # Total episodes for training\n",
    "max_steps = 50000              # Max possible steps in an episode\n",
    "batch_size = 64                # Batch size\n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.00001           # exponential decay rate for exploration prob\n",
    "\n",
    "# Q learning hyperparameters\n",
    "gamma = 0.9                    # Discounting rate\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 1000000          # Number of experiences the Memory can keep\n",
    "\n",
    "### PREPROCESSING HYPERPARAMETERS\n",
    "stack_size = 4                 # Number of frames stacked\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = False\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adım 5: Derin Q-öğrenme Sinir Ağı modelimizi oluşturuyoruz\n",
    "\n",
    "Derin Q-öğrenme modelimiz:\n",
    "\n",
    "Giriş olarak 4 kare yığını alıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            # placeholders(yer tutucuları) oluşturuyoruz\n",
    "            # state_size, state_size öğelerinin her öğesini tuple olarak aldığımız anlamına gelir.\n",
    "            # [None, 84, 84, 4]\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, *state_size], name=\"inputs\")\n",
    "            self.actions_ = tf.placeholder(tf.float32, [None, self.action_size], name=\"actions_\")\n",
    "            \n",
    "            #  target_Q is the R(s,a) + ymax Qhat(s', a')\n",
    "            self.target_Q = tf.placeholder(tf.float32, [None], name=\"target\")\n",
    "            \n",
    "            \"\"\"\n",
    "            ilk Convolutional Neural Network (ConvNet)\n",
    "            \"\"\"\n",
    "            \n",
    "            # Input is 110x84x4\n",
    "            self.conv1 = tf.layers.conv2d(inputs = self.inputs_,\n",
    "                                         filters = 32,\n",
    "                                         kernel_size = [8,8],\n",
    "                                         strides = [4,4],\n",
    "                                         padding = \"VALID\",\n",
    "                                          kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                         name = \"conv1\")\n",
    "            \n",
    "            self.conv1_out = tf.nn.elu(self.conv1, name=\"conv1_out\")\n",
    "            \n",
    "            \"\"\"\n",
    "            ikinci Convolutional Neural Network (ConvNet)\n",
    "            \"\"\"\n",
    "            self.conv2 = tf.layers.conv2d(inputs = self.conv1_out,\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = [4,4],\n",
    "                                 strides = [2,2],\n",
    "                                 padding = \"VALID\",\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                 name = \"conv2\")\n",
    "\n",
    "            self.conv2_out = tf.nn.elu(self.conv2, name=\"conv2_out\")            \n",
    "            \n",
    "            \"\"\"\n",
    "            üçüncü Convolutional Neural Network (ConvNet)\n",
    "            \"\"\"\n",
    "            self.conv3 = tf.layers.conv2d(inputs = self.conv2_out,\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = [3,3],\n",
    "                                 strides = [2,2],\n",
    "                                 padding = \"VALID\",\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                 name = \"conv3\")\n",
    "\n",
    "            self.conv3_out = tf.nn.elu(self.conv3, name=\"conv3_out\")\n",
    "            \n",
    "            self.flatten = tf.contrib.layers.flatten(self.conv3_out)\n",
    "            \n",
    "            self.fc = tf.layers.dense(inputs = self.flatten,\n",
    "                                  units = 512,\n",
    "                                  activation = tf.nn.elu,\n",
    "                                       kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"fc1\")\n",
    "            \n",
    "            self.output = tf.layers.dense(inputs = self.fc, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                          units = self.action_size, \n",
    "                                        activation=None)\n",
    "            \n",
    "\n",
    "  \n",
    "            # Q tahmin edilen Q değerimizdir.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_))\n",
    "            \n",
    "            # Kayıp, tahmin edilen Q_value ve Q_target arasındaki farktır\n",
    "            # Sum(Qtarget - Q)^2\n",
    "            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
